---
title: " Comparison of classification methods for Churn prediction."
output: html_notebook
---

Churn analysis is very importatnt for the companies in order to reduce the customer loss rate. The Churn is the customer taht are leaving the company, which may because of the the product or service they offer or the company behavior. In churn prediction, the purpose is to exmine the cohort who is likely to leave early enough so that the relationship can be saved.

Our objective is to compare various classification methods for the prediction of churn rate.

```{r}
library(ggplot2)
library(gridExtra)
library(class)
library(gmodels)
library(e1071)
library(tree)
library(randomForest)
```


Loading data
```{r}
churn <- read.csv(file.choose(), header = T)
```

making the cgurn variable as factor.
```{r}
churn_v <- as.factor(churn[,"churn"])

churn[,"churn"] <- churn_v


```


```{r}
str(churn)
```

# Ploting variables

```{r}
p1 <- ggplot(churn, aes(number_vmail_messages)) + geom_histogram() + 
      labs(x = "number voice mail messages")

p2 <- ggplot(churn, aes(total_day_charge)) + geom_histogram()+ 
      labs(x = "Total day charge")

grid.arrange(p1, p2, ncol = 2, nrow = 1, top = "")

```

```{r}
p3 <- ggplot(churn, aes(total_eve_charge)) + geom_histogram()+
      labs(x = "Total evening charge")

p4 <- ggplot(churn, aes(total_night_charge)) + geom_histogram()+
      labs(x = "Total night charge")

grid.arrange(p3, p4, ncol = 2, nrow = 1, top = "")

```

```{r}
p5 <- ggplot(churn, aes(total_intl_charge )) + geom_histogram()+
      labs(x = "Total International charge")

p6 <- ggplot(churn, aes(number_customer_service_calls )) + 
      geom_histogram()+ labs(x = "Number customer service calls")

grid.arrange(p5, p6, ncol = 2, nrow = 1, top = "")
```

# Summary

```{r}
summary(churn)
```

# Spliting the data into train and test data
```{r}

samp_siz = floor(0.75 * nrow(churn))

set.seed(123)
train_ind <- sample(seq_len(nrow(churn)), size = samp_siz)

train <- churn[train_ind, ]
test <- churn[-train_ind, ]

```



# Logistic regression
```{r}
mod <- glm(churn~., family = binomial(link = "logit"), data = train )
```

```{r}
summary(mod)
```

From the p-values we can see the that are important.

```{r}
fitted.results <- predict(mod, newdata = subset(test,select=1:7),type='response')

fitted.results <- ifelse(fitted.results > 0.5,1,0)

misClasificError <- mean(fitted.results != test$churn)

print(paste('Accuracy',1-misClasificError))

LR_Accu <- 1-misClasificError

```


# K Nearest Neighbours


```{r}
churn_catag_train <- train[, "churn"] 

churn_catag_test <- test[, "churn"]

train_for_knn <- train[, -8]

test_for_knn  <- test[, -8]

# How to find k value, most common method 

k =round(sqrt(nrow(train_for_knn)),0) 

```


Finding the k value.
```{r}
vec <- numeric(61)
for(i in 1:61){
  knn_mod <- knn(train=train_for_knn, test=test_for_knn, cl =                    churn_catag_train,  k = i)
  tab <- table(knn_mod,churn_catag_test)
  accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
  vec[i] <- accuracy(tab)
  
}

which.max(vec) 

```

K value where the accuracy in highest
```{r}
knn_mod <- knn(train=train, test=test, cl = churn_catag_train,  k = 5)
```

```{r}
tab <- table(knn_mod,churn_catag_test)

accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}

KNN_Accu <- accuracy(tab)
```



# Support vector machine

```{r}
svm_mod <- svm(churn~., data = train, cost = 10, scale = TRUE)

pred <- predict(svm_mod, newdata = test[-8])

tab <- table(pred, test[,8])

accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}

SVM_Accu <- accuracy(tab)

```


# kernel support vector machine (Linear kernel)

```{r}
svm_mod <- svm(churn~., data = train, kernel = 'linear', scale = TRUE)

pred <- predict(svm_mod, newdata = test[-8])

tab <- table(pred, test[,8])

accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}

LinearKerSVM_Accu <- accuracy(tab)
```


# kernel support vector machine (radial kernel)
```{r}
svm_mod <- svm(churn~., data = train, kernel = 'radial', scale = TRUE)

pred <- predict(svm_mod, newdata = test[-8])

tab <- table(pred, test[,8])

accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}

RadialKerSVM_Accu <- accuracy(tab)
```




# Naive Bayes algorithm

```{r}

NaiB_mod <- naiveBayes(churn~., data = train)

pred <- predict(NaiB_mod, test[-8])

tab <- table(pred, test[,8])

accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}

NaiveB_Accu <- accuracy(tab)
```


# Decision tree

```{r}
DT_mod <- tree(churn~., data = train)

pred <- predict(DT_mod,  test[-8], type="class")

tab <- table(pred, test[,8])

accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}

DT_Accu <- accuracy(tab)

```


# Random Forest


```{r}
RF_mod <- randomForest(churn~., data = train)

pred <- predict(RF_mod,  test[-8])

tab <- table(pred, test[,8])

accuracy <- function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}

RF_Accu <- accuracy(tab)
```

Checking important variables
```{r}
 varImpPlot(RF_mod)
```



```{r}
All_methods_acc <- c(LR_Accu, KNN_Accu,SVM_Accu, LinearKerSVM_Accu, RadialKerSVM_Accu, NaiveB_Accu, DT_Accu, RF_Accu)

methods1 <- c('LR_Accu:', 'KNN_Accu','SVM_Accu', 'LinearKerSVM_Accu', 'RadialKerSVM_Accu', 'NaiveB_Accu', 'DT_Accu', 'RF_Accu')
```


```{r}
comp <- as.data.frame(c(methods1))

comp["All_methods_acc "] <- All_methods_acc 

comp
```

Random forest algorithm has the highest accuracy.












